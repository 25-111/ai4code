{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contents\n",
    "\n",
    "- [`AI4Code - EDA & Baseline.ipynb`](#ai4code---eda--baselineipynb): Task description (_Contains TPU Explanation_) & Baseline before EDA\n",
    "- [`Getting Started with AI4Code.ipynb`](#getting-started-with-ai4codeipynb): Just an ordinary competition baseline using XGBoost model\n",
    "- [`AI4Code PyTorch - BERT Large + W&B.ipynb`](#ai4code-pytorch---bert-large--wbipynb): **_Useful_** baseline using Torch-based BERT model\n",
    "- [`AI4Code Pytorch DistilBert Baseline.ipynb`](#ai4code-pytorch-distilbert-baselineipynb): **_Fully-modularized_** baseline using DistilBert model\n",
    "\n",
    "### Additional links\n",
    "\n",
    "- [Huggingface Tutorial](https://www.ohsuz.dev/22f4e8e7-64a3-4789-9dd2-171913883733)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `AI4Code - EDA & Baseline.ipynb`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task description\n",
    "\n",
    "- Visualization\n",
    "\n",
    "  ![](https://storage.googleapis.com/kaggle-media/Images/notebook_cell_examples.png)\n",
    "\n",
    "- Submission format\n",
    "\n",
    "  ```csv\n",
    "  id,cell_order\n",
    "  0009d135ece78d,ddfd239c c6cd22db 1372ae9b ...\n",
    "  0010483c12ba9b,54c7cab3 fe66203e 7844d5f8 ...\n",
    "  0010a919d60e4f,aafc3d23 80e077ec b190ebb4 ...\n",
    "  0028856e09c5b7,012c9d02 d22526d1 3ae7ece3 ...\n",
    "  etc.\n",
    "  ```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Competition evaluation\n",
    "\n",
    "- [Kendall taus correlation](https://en.wikipedia.org/wiki/Kendall_rank_correlation_coefficient)\n",
    "\n",
    "$$\n",
    "K = 1 - 4 \\frac{\\sum_i S_{i}}{\\sum_i n_i(n_i - 1)}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bisect import bisect\n",
    "\n",
    "# Actually O(N^2), but fast in practice for our data\n",
    "def count_inversions(a):\n",
    "    inversions = 0\n",
    "    sorted_so_far = []\n",
    "    for i, u in enumerate(a):  # O(N)\n",
    "        j = bisect(sorted_so_far, u)  # O(log N)\n",
    "        inversions += i - j\n",
    "        sorted_so_far.insert(j, u)  # O(N)\n",
    "    return inversions\n",
    "\n",
    "\n",
    "def calc_kendall_tau(ground_truth, predictions):\n",
    "    total_inversions = 0  # total inversions in predicted ranks across all instances\n",
    "    total_2max = 0  # maximum possible inversions across all instances\n",
    "    for gt, pred in zip(ground_truth, predictions):\n",
    "        ranks = [\n",
    "            gt.index(x) for x in pred\n",
    "        ]  # rank predicted order in terms of ground truth\n",
    "        total_inversions += count_inversions(ranks)\n",
    "        n = len(gt)\n",
    "        total_2max += n * (n - 1)\n",
    "    return 1 - 4 * total_inversions / total_2max\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File information\n",
    "\n",
    "- `train/`\n",
    "\n",
    "  ```json\n",
    "  {\n",
    "    \"cell_type\": {\n",
    "      \"5460dfe1\": \"code\",\n",
    "      \"17d509b0\": \"code\",\n",
    "      \"8861a30e\": \"code\",\n",
    "      \"e2980b77\": \"markdown\",\n",
    "      \"5bcf2a5e\": \"markdown\",\n",
    "      \"5ca5f1a9\": \"markdown\"\n",
    "    },\n",
    "    \"source\": {\n",
    "      \"5460dfe1\": \"!nvidia-smi\",\n",
    "      \"17d509b0\": \"import numpy as np\\n ...\",\n",
    "      \"8861a30e\": \"NUM_CLASSES = 397\\n ...\",\n",
    "      \"e2980b77\": \"# Data\",\n",
    "      \"5bcf2a5e\": \"original kernel\\uff1ahttps://www.kaggle.com/kneroma/clean-fast-simple-bird-identifier-inferenceoriginal\",\n",
    "      \"5ca5f1a9\": \"I tried efficinet B4 B5, but the effect did not improve compared with the original kernel\"\n",
    "    }\n",
    "  }\n",
    "  ```\n",
    "\n",
    "- `train_orders.csv`: Same format as submission format\n",
    "\n",
    "- `train_ancestors.csv`: Forking history of notebooks in the training dataset\n",
    "\n",
    "  ```csv\n",
    "  id,ancestor_id,parent_id\n",
    "  00001756c60be8,945aea18,\n",
    "  00015c83e2717b,aa2da37e,317b65d12af9df\n",
    "  0001bdd4021779,a7711fde,\n",
    "  ```\n",
    "\n",
    "- `test/`: Same format as train dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accelerator setup on Kaggle notebooks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Using TPU\n",
    "try:\n",
    "    # TPU detection. No parameters necessary if TPU_NAME environment variable is set. On Kaggle this is always the case.\n",
    "    TPU = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "except ValueError:\n",
    "    TPU = None\n",
    "\n",
    "if TPU:\n",
    "    print(f\"\\n... RUNNING ON TPU - {TPU.master()}...\")\n",
    "    tf.config.experimental_connect_to_cluster(TPU)\n",
    "    tf.tpu.experimental.initialize_tpu_system(TPU)\n",
    "    strategy = tf.distribute.experimental.TPUStrategy(TPU)\n",
    "else:\n",
    "    print(f\"\\n... RUNNING ON CPU/GPU ...\")\n",
    "    # Yield the default distribution strategy in Tensorflow\n",
    "    #   --> Works on CPU and single GPU.\n",
    "    strategy = tf.distribute.get_strategy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What Is a Replica?\n",
    "#    --> A single Cloud TPU device consists of FOUR chips, each of which has TWO TPU cores.\n",
    "#    --> Therefore, for efficient utilization of Cloud TPU, a program should make use of each of the EIGHT (4x2) cores.\n",
    "#    --> Each replica is essentially a copy of the training graph that is run on each core and\n",
    "#        trains a mini-batch containing 1/8th of the overall batch size\n",
    "N_REPLICAS = strategy.num_replicas_in_sync\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data access on Kaggle notebooks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kaggle_datasets import KaggleDatasets\n",
    "\n",
    "if TPU:\n",
    "    # Google Cloud Dataset path to training and validation images\n",
    "    DATA_DIR = KaggleDatasets().get_gcs_path(\"AI4Code\")\n",
    "    save_locally = tf.saved_model.SaveOptions(experimental_io_device=\"/job:localhost\")\n",
    "    load_locally = tf.saved_model.LoadOptions(experimental_io_device=\"/job:localhost\")\n",
    "else:\n",
    "    # Local path to training and validation images\n",
    "    DATA_DIR = \"/kaggle/input/AI4Code\"\n",
    "    load_locally = save_locally = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use XLA opt on Kaggle notebooks\n",
    "\n",
    "- **XLA** (Accelerated Linear Algebra) is a domain-specific compiler for linear algebra that can accelerate TensorFlow models with potentially no source code changes. The results are improvements in speed and memory usage.\n",
    "- XLA compiles the TensorFlow graph into a sequence of computation kernels generated specifically for the given model. Because these kernels are unique to the model, they can exploit model-specific information for optimization.\n",
    "  - Normally, each TensorFlow operation has a precompiled GPU/TPU kernel implementation that the TensorFlow executor dispatches to.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enable XLA optmizations (10% speedup when using @tf.function calls)\n",
    "tf.config.optimizer.set_jit(True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline codes - Initialization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "# Get json directory paths\n",
    "TRAIN_JSON_DIR = os.path.join(DATA_DIR, \"train\")\n",
    "TEST_JSON_DIR = os.path.join(DATA_DIR, \"test\")\n",
    "\n",
    "# Get all json file paths\n",
    "TRAIN_JSON_PATHS = glob(os.path.join(TRAIN_JSON_DIR, \"*.json\"), recursive=True)\n",
    "TEST_JSON_PATHS = glob(os.path.join(TEST_JSON_DIR, \"*.json\"), recursive=True)\n",
    "\n",
    "# Get number of train and test files\n",
    "N_TRAIN = len(TRAIN_JSON_PATHS)\n",
    "N_TEST = len(TEST_JSON_PATHS)\n",
    "\n",
    "# Get CSV filepaths\n",
    "TRAIN_ANCESTORS_CSV = os.path.join(DATA_DIR, \"train_ancestors.csv\")\n",
    "TRAIN_ORDERS_CSV = os.path.join(DATA_DIR, \"train_orders.csv\")\n",
    "SS_CSV = os.path.join(DATA_DIR, \"sample_submission.csv\")\n",
    "\n",
    "# Convert CSV into dataframe\n",
    "train_ancestors_df = pd.read_csv(TRAIN_ANCESTORS_CSV)\n",
    "train_orders_df = pd.read_csv(TRAIN_ORDERS_CSV)\n",
    "ss_df = pd.read_csv(SS_CSV)\n",
    "\n",
    "print(\"\\n... TRAIN ANCESTORS DATAFRAME... \\n\")\n",
    "display(train_ancestors_df)\n",
    "\n",
    "print(\"\\n... TRAIN ORDERS DATAFRAME... \\n\")\n",
    "display(train_orders_df)\n",
    "\n",
    "print(\"\\n\\n\\n... ORIGINAL SUBMISSION DATAFRAME... \\n\")\n",
    "display(ss_df)\n",
    "\n",
    "# For debugging purposes when the test set hasn't been substituted we will know\n",
    "DEBUG = len(ss_df) == 4\n",
    "\n",
    "\n",
    "print(\"\\n... BASIC DATA SETUP FINISHED ...\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "FIRST_RUN = not os.path.isfile(\"/kaggle/input/ai4code-train-dataframe/train.csv\")\n",
    "\n",
    "\n",
    "def load_json_to_df(all_fpaths, do_parallel=True):\n",
    "    def __fpath_to_df(fpath):\n",
    "        tmp_df = (\n",
    "            pd.read_json(fpath, dtype={\"cell_type\": \"category\", \"source\": \"str\"})\n",
    "            .reset_index()\n",
    "            .rename({\"index\": \"cell_id\"}, axis=1)\n",
    "        )\n",
    "        tmp_df[\"id\"] = fpath.rsplit(\".\", 1)[0].rsplit(\"/\", 1)[-1]\n",
    "        return tmp_df\n",
    "\n",
    "    if do_parallel:\n",
    "        all_example_dfs = Parallel()(\n",
    "            delayed(__fpath_to_df)(fpath)\n",
    "            for fpath in tqdm(all_fpaths, total=len(all_fpaths))\n",
    "        )\n",
    "    else:\n",
    "        all_example_dfs = [\n",
    "            __fpath_to_df(fpath) for fpath in tqdm(all_fpaths, total=len(all_fpaths))\n",
    "        ]\n",
    "    return pd.concat(all_example_dfs).reset_index(drop=True)\n",
    "\n",
    "\n",
    "if FIRST_RUN:\n",
    "    print(\"\\n... CREATING TRAIN AND TEST DATAFRAMES (20-30 MINUTES) ...\\n\")\n",
    "    train_df = load_json_to_df(TRAIN_JSON_PATHS, do_parallel=False)\n",
    "    train_df = train_df[[\"id\", \"cell_id\", \"cell_type\", \"source\"]]\n",
    "    train_df.to_csv(\n",
    "        \"train.csv\", index=False, encoding=\"utf-8\", quoting=csv.QUOTE_NONNUMERIC\n",
    "    )\n",
    "else:\n",
    "    print(\n",
    "        \"\\n... LOADING TRAIN DATAFRAME AND CREATING TEST DATAFRAME (1-3 MINUTES) ...\\n\"\n",
    "    )\n",
    "    train_df = pd.read_csv(\n",
    "        \"/kaggle/input/ai4code-train-dataframe/train.csv\", keep_default_na=False\n",
    "    )\n",
    "\n",
    "test_df = load_json_to_df(TEST_JSON_PATHS)\n",
    "test_df = test_df[[\"id\", \"cell_id\", \"cell_type\", \"source\"]]\n",
    "\n",
    "print(\"\\n... ALL TRAIN EXAMPLES AS A DATAFRAME ...\\n\\n\")\n",
    "display(train_df)\n",
    "\n",
    "print(\"\\n\\n\\n\\n... ALL TEST EXAMPLES AS A DATAFRAME ...\\n\\n\")\n",
    "display(train_df)\n",
    "\n",
    "print(\n",
    "    \"\\n\\n\\n\\n... VIEW THE ROWS THAT WERE PREVIOUSLY CAUSING PROBLEMS THAT CONTAIN NAN LIKE STRINGS ...\\n\\n\"\n",
    ")\n",
    "nan_weirdos = [2076836, 2915099, 3416950, 4260446]\n",
    "for row_idx in nan_weirdos:\n",
    "    _row = train_df.iloc[row_idx]\n",
    "    with open([x for x in TRAIN_JSON_PATHS if _row[\"id\"] in x][0]) as json_file:\n",
    "        data = json.load(json_file)\n",
    "        print(\n",
    "            f\"ROW INDEX: {row_idx}\\nSOURCE IN OUR DATAFRAME        : \", _row[\"source\"]\n",
    "        )\n",
    "        print(\n",
    "            \"SOURCE DIRECTLY FROM JSON FIL E: \", data[\"source\"][_row[\"cell_id\"]], \"\\n\"\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline codes - Utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Code, Markdown, Pretty\n",
    "\n",
    "\n",
    "def flatten_l_o_l(nested_list):\n",
    "    \"\"\"Flatten a nested list of lists\"\"\"\n",
    "    return [item for sublist in nested_list for item in sublist]\n",
    "\n",
    "\n",
    "def display_markdown(markdown_str):\n",
    "    \"\"\"Wrapper function to display markdown as output of code cell\"\"\"\n",
    "    display(Markdown(markdown_str))\n",
    "\n",
    "\n",
    "def display_code(code_str):\n",
    "    \"\"\"Wrapper function to display markdown as output of code cell\"\"\"\n",
    "    display(Code(code_str))\n",
    "\n",
    "\n",
    "def get_ex_order(ex_id, orders_df=train_orders_df):\n",
    "    return orders_df[orders_df[\"id\"] == ex_id].cell_order.values[0].split()\n",
    "\n",
    "\n",
    "def display_notebook(\n",
    "    ex_id=None,\n",
    "    df=train_df,\n",
    "    show_ordered=True,\n",
    "    render_markdown=True,\n",
    "    order_df=train_orders_df,\n",
    "):\n",
    "    \"\"\"Function to allow for visualization of a complete notebook\"\"\"\n",
    "\n",
    "    # Get random ex_id if not provided\n",
    "    if ex_id is None:\n",
    "        ex_id = df[\"id\"].sample(1).values[0]\n",
    "    print(\n",
    "        f\"\\n\\n\\n\\n... INVESTIGATING AND VISUALIZING EXAMPLE {ex_id} –– CELLS WILL BE {'ORDERED' if show_ordered else 'UNORDERED'} ...\\n\\n\\n\\n\"\n",
    "    )\n",
    "\n",
    "    # Get unordered subset of  dataframe\n",
    "    u_sub_df = df[df[\"id\"] == ex_id].reset_index(drop=True)\n",
    "\n",
    "    # Get unordered subset of dataframe\n",
    "    if show_ordered:\n",
    "        cell_id_sorter = {c_id: i for i, c_id in enumerate(get_ex_order(ex_id))}\n",
    "        u_sub_df[\"sorter\"] = u_sub_df.cell_id.map(cell_id_sorter)\n",
    "        o_sub_df = (\n",
    "            u_sub_df.sort_values(by=\"sorter\")\n",
    "            .reset_index(drop=True)\n",
    "            .drop(columns=[\"sorter\"])\n",
    "        )\n",
    "\n",
    "    for i, (_, row) in enumerate(\n",
    "        u_sub_df.iterrows() if not show_ordered else o_sub_df.iterrows()\n",
    "    ):\n",
    "        print(\"\\n\\n\")\n",
    "        display_markdown(\"---\")\n",
    "        print()\n",
    "        display_markdown(\n",
    "            f\"{'----- '+'CELL '+str(i+1)+' OF TYPE '+str(row.cell_type.upper())+' -----':^120}\"\n",
    "        )\n",
    "        display_markdown(\"---\")\n",
    "        print()\n",
    "        if render_markdown:\n",
    "            display_markdown(row[\"source\"]) if row[\n",
    "                \"cell_type\"\n",
    "            ] == \"markdown\" else display_code(row[\"source\"])\n",
    "        else:\n",
    "            display_code(row[\"source\"])\n",
    "        print()\n",
    "        display_markdown(\"---\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline codes - Feature engineering\n",
    "\n",
    "- Number of total cells\n",
    "- Number of code cells\n",
    "- Number of markdown cells\n",
    "- Fraction of code cells\n",
    "- Fraction of markdown cells\n",
    "- Position of cell in notebook (ground truth if known)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There's definitely a faster way to do this with grouping then applying then ungrouping\n",
    "def add_style_specific_counts(df=train_df):\n",
    "    id_w_style_to_count = (\n",
    "        df.groupby(df[\"id\"] + \"_\" + df[\"cell_type\"])[\"source\"]\n",
    "        .count()\n",
    "        .reset_index()\n",
    "        .groupby(\"index\")\n",
    "        .first()[\"source\"]\n",
    "        .to_dict()\n",
    "    )\n",
    "    df[\"n_code_cells\"] = (df[\"id\"] + \"_code\").progress_apply(\n",
    "        lambda x: id_w_style_to_count.get(x, 0)\n",
    "    )\n",
    "    df[\"n_markdown_cells\"] = (df[\"id\"] + \"_markdown\").progress_apply(\n",
    "        lambda x: id_w_style_to_count.get(x, 0)\n",
    "    )\n",
    "    return df\n",
    "\n",
    "\n",
    "def add_position_information(df=train_df, orders_df=train_orders_df):\n",
    "    all_cell_ids_in_order = orders_df.cell_order.apply(lambda x: x.split()).to_list()\n",
    "    all_cell_pos = flatten_l_o_l(\n",
    "        [range(len(sub_cell_ids)) for sub_cell_ids in all_cell_ids_in_order]\n",
    "    )\n",
    "    all_cell_ids_in_order = flatten_l_o_l(all_cell_ids_in_order)\n",
    "    cell_id_2_pos = {\n",
    "        c_id: pos for c_id, pos in zip(all_cell_ids_in_order, all_cell_pos)\n",
    "    }\n",
    "    df.insert(4, \"cell_pos\", df[\"cell_id\"].map(cell_id_2_pos))\n",
    "    return df\n",
    "\n",
    "\n",
    "train_df = add_position_information(train_df)\n",
    "train_df[\"n_total_cells\"] = train_df.groupby(\"id\")[\"source\"].transform(\"count\")\n",
    "train_df[\"relative_position\"] = (train_df[\"cell_pos\"] + 1) / train_df[\"n_total_cells\"]\n",
    "train_df = add_style_specific_counts(train_df)\n",
    "train_df[\"code_fraction\"] = train_df[\"n_code_cells\"] / train_df[\"n_total_cells\"]\n",
    "train_df[\"markdown_fraction\"] = train_df[\"n_markdown_cells\"] / train_df[\"n_total_cells\"]\n",
    "\n",
    "test_df[\"n_total_cells\"] = test_df.groupby(\"id\")[\"source\"].transform(\"count\")\n",
    "test_df = add_style_specific_counts(test_df)\n",
    "test_df[\"code_fraction\"] = test_df[\"n_code_cells\"] / test_df[\"n_total_cells\"]\n",
    "test_df[\"markdown_fraction\"] = test_df[\"n_markdown_cells\"] / test_df[\"n_total_cells\"]\n",
    "\n",
    "train_meta_df = train_df.drop_duplicates(\"id\").reset_index(drop=True)[\n",
    "    [\n",
    "        \"id\",\n",
    "        \"n_total_cells\",\n",
    "        \"n_code_cells\",\n",
    "        \"n_markdown_cells\",\n",
    "        \"code_fraction\",\n",
    "        \"markdown_fraction\",\n",
    "    ]\n",
    "]\n",
    "test_meta_df = test_df.drop_duplicates(\"id\").reset_index(drop=True)[\n",
    "    [\n",
    "        \"id\",\n",
    "        \"n_total_cells\",\n",
    "        \"n_code_cells\",\n",
    "        \"n_markdown_cells\",\n",
    "        \"code_fraction\",\n",
    "        \"markdown_fraction\",\n",
    "    ]\n",
    "]\n",
    "\n",
    "display(train_df.head())\n",
    "display(test_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline codes - EDA\n",
    "\n",
    "1. Investigate distribution\n",
    "   - The lengths of the notebooks as described by total cell count, markdown cell count, and code cell count, all skew heavily towards shorter rather than longer.\n",
    "     - n_total_cells has a mean of only **45.75** while the maximum value is **over 1000**\n",
    "     - Similar patterns are seen within n_code_cells and n_markdown_cells\n",
    "   - There are certain heuristic rules that always exist:\n",
    "     - There are always at least 2 cells per notebook\n",
    "     - There are always at least 1 code cell per notebook\n",
    "     - There are always at least 1 markdown cell per notebook\n",
    "   - Some observations can be gleaned contrasting notebook and markdown cells\n",
    "     - Notebook cells are more than twice as common as Markdown cells (67% vs. 33%)\n",
    "       - i.e. The average notebook is comprised of ~30.2 notebook cells and ~15.5 markdown cells (based on the average total notebook length of ~45.7 cells.\n",
    "     - Some notebook are almost entirely code cells (a fraction of 99.7% of cells)\n",
    "     - Some notebook are almost entirely markdown cells (a fraction of 98.8% of cells)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "display(train_meta_df.describe().T)\n",
    "\n",
    "fig = px.histogram(\n",
    "    train_meta_df,\n",
    "    [\"n_total_cells\"],\n",
    "    title=\"<b>Number of Total Cells Per Notebook  <sub><i>Log Y-Axis</i></sub></b>\",\n",
    "    nbins=200,\n",
    "    marginal=\"violin\",\n",
    "    log_y=True,\n",
    ")\n",
    "fig.update_layout(showlegend=False)\n",
    "fig.show()\n",
    "\n",
    "fig = px.histogram(\n",
    "    train_meta_df,\n",
    "    [\"n_code_cells\", \"n_markdown_cells\"],\n",
    "    barmode=\"overlay\",\n",
    "    title=\"<b>Number of Markdown v. Code Cells Per Notebook  <sub><i>Log Y-Axis</i></sub></b>\",\n",
    "    nbins=200,\n",
    "    marginal=\"violin\",\n",
    "    log_y=True,\n",
    ")\n",
    "fig.update_layout(showlegend=False)\n",
    "fig.show()\n",
    "\n",
    "fig = px.histogram(\n",
    "    train_meta_df,\n",
    "    [\"code_fraction\", \"markdown_fraction\"],\n",
    "    barmode=\"overlay\",\n",
    "    title=\"<b>Distribution of Fractional Composition of Markdown v. Code Cells Per Notebook  <sub><i>Log Y-Axis</i></sub></b>\",\n",
    "    nbins=200,\n",
    "    marginal=\"violin\",\n",
    "    log_y=True,\n",
    ")\n",
    "fig.update_layout(showlegend=False)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Investigate lengths of individual cell blocks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"n_cell_chars\"] = train_df[\"source\"].progress_apply(len)\n",
    "train_df.describe().T\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Fix base64 image blocks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def remove_long_useless_strs(src):\n",
    "    delim_pairs = [\n",
    "        (\";base64,\", '\\\\\"'),\n",
    "        (\";base64,\", \"\\)\"),\n",
    "        (\"weight = b'\", \"'\"),\n",
    "        (\"PARAM = b'\", \"'\"),\n",
    "    ]\n",
    "\n",
    "    for delim_1, delim_2 in delim_pairs:\n",
    "        src = re.sub(f\"{delim_1}.*?{delim_2}\", \"(replaced)\", src, flags=re.DOTALL)\n",
    "    return src\n",
    "\n",
    "\n",
    "train_df[\"source\"] = train_df[\"source\"].progress_apply(remove_long_useless_strs)\n",
    "train_df[\"n_cell_chars\"] = train_df[\"source\"].progress_apply(len)\n",
    "train_df.describe().T\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling\n",
    "\n",
    "- Leverage `TFIDF` and `XGBRanker`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CREATE TRAIN/VAL SPLITS\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "\n",
    "# Apply merge\n",
    "train_df = pd.merge(\n",
    "    train_df, train_ancestors_df[[\"id\", \"ancestor_id\"]], on=\"id\", how=\"left\"\n",
    ")\n",
    "\n",
    "VAL_FRAC = 0.1\n",
    "FEAT_COLS = [\n",
    "    \"id\",\n",
    "    \"cell_id\",\n",
    "    \"cell_type\",\n",
    "    \"source\",\n",
    "    \"n_total_cells\",\n",
    "    \"n_code_cells\",\n",
    "    \"n_markdown_cells\",\n",
    "    \"code_fraction\",\n",
    "    \"markdown_fraction\",\n",
    "    \"n_cell_chars\",\n",
    "]\n",
    "LABEL_COLS = [\"cell_pos\"]  # or relative position\n",
    "GROUP_COLS = [\"ancestor_id\"]\n",
    "g_splitter = GroupShuffleSplit(n_splits=1, test_size=VAL_FRAC, random_state=0)\n",
    "\n",
    "# Split, keeping notebooks with a common origin (ancestor_id) together\n",
    "train_ids, val_ids = next(\n",
    "    g_splitter.split(\n",
    "        train_df[FEAT_COLS], train_df[LABEL_COLS], groups=train_df[GROUP_COLS]\n",
    "    )\n",
    ")\n",
    "ids_train, ids_valid = ids[ids_train], ids[ids_valid]\n",
    "\n",
    "val_df = train_df.iloc[val_ids].reset_index(drop=True)\n",
    "train_df = train_df.iloc[train_ids].reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CONVERT TO CUDF TO FREE MEMORY AND PREPARE FOR MODELLING\n",
    "import gc\n",
    "import cudf, cupy, cuml\n",
    "\n",
    "val_df = cudf.from_pandas(val_df)\n",
    "train_df = cudf.from_pandas(train_df)\n",
    "gc.collect()\n",
    "gc.collect()\n",
    "\n",
    "train_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `Getting Started with AI4Code.ipynb`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setup\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "from tqdm import tqdm\n",
    "\n",
    "pd.options.display.width = 180\n",
    "pd.options.display.max_colwidth = 120\n",
    "\n",
    "data_dir = Path(\"../input/AI4Code\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load data\n",
    "NUM_TRAIN = 10000\n",
    "\n",
    "\n",
    "def read_notebook(path):\n",
    "    return (\n",
    "        pd.read_json(path, dtype={\"cell_type\": \"category\", \"source\": \"str\"})\n",
    "        .assign(id=path.stem)\n",
    "        .rename_axis(\"cell_id\")\n",
    "    )\n",
    "\n",
    "\n",
    "paths_train = list((data_dir / \"train\").glob(\"*.json\"))[:NUM_TRAIN]\n",
    "notebooks_train = [read_notebook(path) for path in tqdm(paths_train, desc=\"Train NBs\")]\n",
    "df = (\n",
    "    pd.concat(notebooks_train)\n",
    "    .set_index(\"id\", append=True)\n",
    "    .swaplevel()\n",
    "    .sort_index(level=\"id\", sort_remaining=False)\n",
    ")\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_id = df.index.unique(\"id\")[6]\n",
    "print(\"Notebook:\", nb_id)\n",
    "\n",
    "print(\"The disordered notebook:\")\n",
    "nb = df.loc[nb_id, :]\n",
    "display(nb)\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Order the cells\n",
    "df_orders = pd.read_csv(\n",
    "    data_dir / \"train_orders.csv\",\n",
    "    index_col=\"id\",\n",
    "    squeeze=True,\n",
    ").str.split()  # Split the string representation of cell_ids into a list\n",
    "\n",
    "cell_order = df_orders.loc[nb_id]\n",
    "\n",
    "nb.loc[cell_order, :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Order the cells in an alternative way\n",
    "def get_ranks(base, derived):\n",
    "    return [base.index(d) for d in derived]\n",
    "\n",
    "\n",
    "cell_ranks = get_ranks(cell_order, list(nb.index))\n",
    "nb.insert(0, \"rank\", cell_ranks)\n",
    "\n",
    "nb.sort_values(\"rank\")  # sort by rank\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orders_ = df_orders.to_frame().join(\n",
    "    df.reset_index(\"cell_id\").groupby(\"id\")[\"cell_id\"].apply(list),\n",
    "    how=\"right\",\n",
    ")\n",
    "\n",
    "ranks = {\n",
    "    id_: {\"cell_id\": cell_id, \"rank\": get_ranks(cell_order, cell_id)}\n",
    "    for id_, cell_order, cell_id in df_orders_.itertuples()\n",
    "}\n",
    "\n",
    "df_ranks = (\n",
    "    pd.DataFrame.from_dict(ranks, orient=\"index\")\n",
    "    .rename_axis(\"id\")\n",
    "    .apply(pd.Series.explode)\n",
    "    .set_index(\"cell_id\", append=True)\n",
    ")\n",
    "\n",
    "df_ranks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Split\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "\n",
    "df_ancestors = pd.read_csv(data_dir / \"train_ancestors.csv\", index_col=\"id\")\n",
    "\n",
    "NVALID = 0.1  # size of validation set\n",
    "splitter = GroupShuffleSplit(n_splits=1, test_size=NVALID, random_state=0)\n",
    "\n",
    "# Split, keeping notebooks with a common origin (ancestor_id) together\n",
    "ids = df.index.unique(\"id\")\n",
    "ancestors = df_ancestors.loc[ids, \"ancestor_id\"]\n",
    "ids_train, ids_valid = next(splitter.split(ids, groups=ancestors))\n",
    "ids_train, ids_valid = ids[ids_train], ids[ids_valid]\n",
    "\n",
    "df_train = df.loc[ids_train, :]\n",
    "df_valid = df.loc[ids_valid, :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Feature engineering\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(min_df=0.01)\n",
    "X_train = tfidf.fit_transform(df_train[\"source\"].astype(str))\n",
    "\n",
    "# Rank of each cell within the notebook\n",
    "y_train = df_ranks.loc[ids_train].to_numpy()\n",
    "\n",
    "# Number of cells in each notebook\n",
    "groups = df_ranks.loc[ids_train].groupby(\"id\").size().to_numpy()\n",
    "\n",
    "# Add code cell ordering\n",
    "X_train = sparse.hstack(\n",
    "    (\n",
    "        X_train,\n",
    "        np.where(\n",
    "            df_train[\"cell_type\"] == \"code\",\n",
    "            df_train.groupby([\"id\", \"cell_type\"]).cumcount().to_numpy() + 1,\n",
    "            0,\n",
    "        ).reshape(-1, 1),\n",
    "    )\n",
    ")\n",
    "print(X_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train\n",
    "from xgboost import XGBRanker\n",
    "\n",
    "model = XGBRanker(\n",
    "    min_child_weight=10,\n",
    "    subsample=0.5,\n",
    "    tree_method=\"hist\",\n",
    ")\n",
    "model.fit(X_train, y_train, group=groups)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Evaluate\n",
    "X_valid = tfidf.transform(df_valid[\"source\"].astype(str))\n",
    "y_valid = df_orders.loc[ids_valid]  # The metric uses cell ids\n",
    "\n",
    "X_valid = sparse.hstack(\n",
    "    (\n",
    "        X_valid,\n",
    "        np.where(\n",
    "            df_valid[\"cell_type\"] == \"code\",\n",
    "            df_valid.groupby([\"id\", \"cell_type\"]).cumcount().to_numpy() + 1,\n",
    "            0,\n",
    "        ).reshape(-1, 1),\n",
    "    )\n",
    ")\n",
    "\n",
    "y_pred = pd.DataFrame({\"rank\": model.predict(X_valid)}, index=df_valid.index)\n",
    "y_pred = (\n",
    "    y_pred.sort_values([\"id\", \"rank\"])  # Sort the cells in each notebook by their rank.\n",
    "    # The cell_ids are now in the order the model predicted.\n",
    "    .reset_index(\"cell_id\")  # Convert the cell_id index into a column.\n",
    "    .groupby(\"id\")[\"cell_id\"]\n",
    "    .apply(list)  # Group the cell_ids for each notebook into a list.\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Metric\n",
    "y_dummy = df_valid.reset_index(\"cell_id\").groupby(\"id\")[\"cell_id\"].apply(list)\n",
    "calc_kendall_tau(y_valid, y_dummy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Submission\n",
    "paths_test = list((data_dir / \"test\").glob(\"*.json\"))\n",
    "notebooks_test = [read_notebook(path) for path in tqdm(paths_test, desc=\"Test NBs\")]\n",
    "df_test = (\n",
    "    pd.concat(notebooks_test)\n",
    "    .set_index(\"id\", append=True)\n",
    "    .swaplevel()\n",
    "    .sort_index(level=\"id\", sort_remaining=False)\n",
    ")\n",
    "\n",
    "X_test = tfidf.transform(df_test[\"source\"].astype(str))\n",
    "X_test = sparse.hstack(\n",
    "    (\n",
    "        X_test,\n",
    "        np.where(\n",
    "            df_test[\"cell_type\"] == \"code\",\n",
    "            df_test.groupby([\"id\", \"cell_type\"]).cumcount().to_numpy() + 1,\n",
    "            0,\n",
    "        ).reshape(-1, 1),\n",
    "    )\n",
    ")\n",
    "\n",
    "y_infer = pd.DataFrame({\"rank\": model.predict(X_test)}, index=df_test.index)\n",
    "y_infer = (\n",
    "    y_infer.sort_values([\"id\", \"rank\"])\n",
    "    .reset_index(\"cell_id\")\n",
    "    .groupby(\"id\")[\"cell_id\"]\n",
    "    .apply(list)\n",
    ")\n",
    "\n",
    "y_sample = pd.read_csv(data_dir / \"sample_submission.csv\", index_col=\"id\", squeeze=True)\n",
    "\n",
    "y_submit = (\n",
    "    y_infer.apply(\" \".join)  # list of ids -> string of ids\n",
    "    .rename_axis(\"id\")\n",
    "    .rename(\"cell_order\")\n",
    ")\n",
    "y_submit.to_csv(\"submission.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `AI4Code PyTorch - BERT Large + W&B.ipynb`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setup model\n",
    "from pathlib import Path\n",
    "import transformers\n",
    "from torch.cuda.amp import GradScaler\n",
    "\n",
    "\n",
    "class Config:\n",
    "    NB_EPOCHS = 2\n",
    "    LR = 3e-4\n",
    "    T_0 = 20\n",
    "    η_min = 1e-4\n",
    "    MAX_LEN = 120\n",
    "    TRAIN_BS = 16\n",
    "    VALID_BS = 16\n",
    "    MODEL_NAME = \"bert-large-uncased\"\n",
    "    data_dir = Path(\"../input/AI4Code\")\n",
    "    TOKENIZER = transformers.BertTokenizer.from_pretrained(\n",
    "        MODEL_NAME, do_lower_case=True\n",
    "    )\n",
    "    scaler = GradScaler()\n",
    "    wandb = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setup WandB\n",
    "import wandb\n",
    "\n",
    "WANDB_CONFIG = {\n",
    "    \"TRAIN_BS\": Config.TRAIN_BS,\n",
    "    \"VALID_BS\": Config.VALID_BS,\n",
    "    \"N_EPOCHS\": Config.NB_EPOCHS,\n",
    "    \"ARCH\": Config.MODEL_NAME,\n",
    "    \"MAX_LEN\": Config.MAX_LEN,\n",
    "    \"LR\": Config.LR,\n",
    "    \"NUM_WORKERS\": 8,\n",
    "    \"OPTIM\": \"AdamW\",\n",
    "    \"LOSS\": \"MSELoss\",\n",
    "    \"DEVICE\": \"cuda\",\n",
    "    \"T_0\": 20,\n",
    "    \"η_min\": 1e-4,\n",
    "    \"infra\": \"Kaggle\",\n",
    "    \"competition\": \"ai4code\",\n",
    "    \"_wandb_kernel\": \"tanaym\",\n",
    "}\n",
    "\n",
    "if Config.wandb:\n",
    "    from kaggle_secrets import UserSecretsClient\n",
    "\n",
    "    user_secrets = UserSecretsClient()\n",
    "    wb_key = user_secrets.get_secret(\"WANDB_API_KEY\")\n",
    "\n",
    "    wandb.login(key=wb_key)\n",
    "\n",
    "    run = wandb.init(\n",
    "        project=\"pytorch\",\n",
    "        config=WANDB_CONFIG,\n",
    "        group=\"nlp\",\n",
    "        job_type=\"train\",\n",
    "    )\n",
    "\n",
    "\n",
    "def wandb_log(**kwargs):\n",
    "    \"\"\"Logs a key-value pair to W&B\"\"\"\n",
    "    for k, v in kwargs.items():\n",
    "        wandb.log({k: v})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Preprocessing\n",
    "NUM_TRAIN = 15000\n",
    "\n",
    "paths_train = list((Config.data_dir / \"train\").glob(\"*.json\"))[:NUM_TRAIN]\n",
    "notebooks_train = [read_notebook(path) for path in tqdm(paths_train, desc=\"Train NBs\")]\n",
    "df = (\n",
    "    pd.concat(notebooks_train)\n",
    "    .set_index(\"id\", append=True)\n",
    "    .swaplevel()\n",
    "    .sort_index(level=\"id\", sort_remaining=False)\n",
    ")\n",
    "\n",
    "df_orders = pd.read_csv(\n",
    "    Config.data_dir / \"train_orders.csv\",\n",
    "    index_col=\"id\",\n",
    "    squeeze=True,\n",
    ").str.split()\n",
    "\n",
    "df_orders_ = df_orders.to_frame().join(\n",
    "    df.reset_index(\"cell_id\").groupby(\"id\")[\"cell_id\"].apply(list),\n",
    "    how=\"right\",\n",
    ")\n",
    "\n",
    "ranks = {}\n",
    "for id_, cell_order, cell_id in df_orders_.itertuples():\n",
    "    ranks[id_] = {\"cell_id\": cell_id, \"rank\": get_ranks(cell_order, cell_id)}\n",
    "\n",
    "df_ranks = (\n",
    "    pd.DataFrame.from_dict(ranks, orient=\"index\")\n",
    "    .rename_axis(\"id\")\n",
    "    .apply(pd.Series.explode)\n",
    "    .set_index(\"cell_id\", append=True)\n",
    ")\n",
    "\n",
    "df_ancestors = pd.read_csv(Config.data_dir / \"train_ancestors.csv\", index_col=\"id\")\n",
    "df = (\n",
    "    df.reset_index()\n",
    "    .merge(df_ranks, on=[\"id\", \"cell_id\"])\n",
    "    .merge(df_ancestors, on=[\"id\"])\n",
    ")\n",
    "df[\"pct_rank\"] = df[\"rank\"] / df.groupby(\"id\")[\"cell_id\"].transform(\"count\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NVALID = 0.1  # size of validation set\n",
    "\n",
    "splitter = GroupShuffleSplit(n_splits=1, test_size=NVALID, random_state=0)\n",
    "\n",
    "train_ind, val_ind = next(splitter.split(df, groups=df[\"ancestor_id\"]))\n",
    "\n",
    "train_df = df.loc[train_ind].reset_index(drop=True)\n",
    "val_df = df.loc[val_ind].reset_index(drop=True)\n",
    "\n",
    "train_df_mark = train_df[train_df[\"cell_type\"] == \"markdown\"].reset_index(drop=True)\n",
    "val_df_mark = val_df[val_df[\"cell_type\"] == \"markdown\"].reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class BERTLargeModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BERTLargeModel, self).__init__()\n",
    "        self.bert = transformers.BertModel.from_pretrained(Config.MODEL_NAME)\n",
    "        self.drop = nn.Dropout(0.3)\n",
    "        self.fc = nn.Linear(1024, 1)\n",
    "\n",
    "    def forward(self, ids, mask, token_type_ids):\n",
    "        _, output = self.bert(\n",
    "            ids, attention_mask=mask, token_type_ids=token_type_ids, return_dict=False\n",
    "        )\n",
    "        output = self.drop(output)\n",
    "        output = self.fc(output)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Custom Dataset class\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "class AI4CodeDataset(Dataset):\n",
    "    def __init__(self, df, is_test=False):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.is_test = is_test\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.df.iloc[idx]\n",
    "\n",
    "        inputs = Config.TOKENIZER.encode_plus(\n",
    "            sample[\"source\"],\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=Config.MAX_LEN,\n",
    "            padding=\"max_length\",\n",
    "            return_token_type_ids=True,\n",
    "            truncation=True,\n",
    "        )\n",
    "        ids = torch.tensor(inputs[\"input_ids\"], dtype=torch.long)\n",
    "        mask = torch.tensor(inputs[\"attention_mask\"], dtype=torch.long)\n",
    "        token_type_ids = torch.tensor(inputs[\"token_type_ids\"], dtype=torch.long)\n",
    "\n",
    "        if self.is_test:\n",
    "            return (ids, mask, token_type_ids)\n",
    "        else:\n",
    "            targets = torch.tensor([sample.pct_rank], dtype=torch.float)\n",
    "            return (ids, mask, token_type_ids, targets)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Trainer class and optimizer-returning function\n",
    "from torch.cuda.amp import autocast\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "class Trainer:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config,\n",
    "        dataloaders,\n",
    "        optimizer,\n",
    "        model,\n",
    "        wandb,\n",
    "        loss_fns,\n",
    "        scheduler,\n",
    "        device=\"cuda:0\",\n",
    "    ):\n",
    "        self.train_loader, self.valid_loader = dataloaders\n",
    "        self.train_loss_fn, self.valid_loss_fn = loss_fns\n",
    "        self.scheduler = scheduler\n",
    "        self.optimizer = optimizer\n",
    "        self.model = model\n",
    "        self.wandb = wandb\n",
    "        self.device = torch.device(device)\n",
    "        self.config = config\n",
    "\n",
    "    def train_one_epoch(self):\n",
    "        \"\"\"\n",
    "        Trains the model for 1 epoch\n",
    "        \"\"\"\n",
    "        self.model.train()\n",
    "        train_pbar = tqdm(enumerate(self.train_loader), total=len(self.train_loader))\n",
    "        train_preds, train_targets = [], []\n",
    "\n",
    "        for bnum, cache in train_pbar:\n",
    "            ids = self._convert_if_not_tensor(cache[0], dtype=torch.long)\n",
    "            mask = self._convert_if_not_tensor(cache[1], dtype=torch.long)\n",
    "            ttis = self._convert_if_not_tensor(cache[2], dtype=torch.long)\n",
    "            targets = self._convert_if_not_tensor(cache[3], dtype=torch.float)\n",
    "\n",
    "            with autocast(enabled=True):\n",
    "                outputs = self.model(ids=ids, mask=mask, token_type_ids=ttis).view(-1)\n",
    "\n",
    "                loss = self.train_loss_fn(outputs, targets)\n",
    "                loss_itm = loss.item()\n",
    "\n",
    "                if self.wandb:\n",
    "                    wandb_log(train_batch_loss=loss_itm)\n",
    "\n",
    "                train_pbar.set_description(\"loss: {:.2f}\".format(loss_itm))\n",
    "\n",
    "                Config.scaler.scale(loss).backward()\n",
    "                Config.scaler.step(self.optimizer)\n",
    "                Config.scaler.update()\n",
    "                self.optimizer.zero_grad()\n",
    "                self.scheduler.step()\n",
    "\n",
    "            train_targets.extend(targets.cpu().detach().numpy().tolist())\n",
    "            train_preds.extend(outputs.cpu().detach().numpy().tolist())\n",
    "\n",
    "        # Tidy\n",
    "        del outputs, targets, ids, mask, ttis, loss_itm, loss\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        return train_preds, train_targets\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def valid_one_epoch(self):\n",
    "        \"\"\"\n",
    "        Validates the model for 1 epoch\n",
    "        \"\"\"\n",
    "        self.model.eval()\n",
    "        valid_pbar = tqdm(enumerate(self.valid_loader), total=len(self.valid_loader))\n",
    "        valid_preds, valid_targets = [], []\n",
    "\n",
    "        for idx, cache in valid_pbar:\n",
    "            ids = self._convert_if_not_tensor(cache[0], dtype=torch.long)\n",
    "            mask = self._convert_if_not_tensor(cache[1], dtype=torch.long)\n",
    "            ttis = self._convert_if_not_tensor(cache[2], dtype=torch.long)\n",
    "            targets = self._convert_if_not_tensor(cache[3], dtype=torch.float)\n",
    "\n",
    "            outputs = self.model(ids=ids, mask=mask, token_type_ids=ttis).view(-1)\n",
    "            valid_loss = self.valid_loss_fn(outputs, targets)\n",
    "\n",
    "            if self.wandb:\n",
    "                wandb_log(valid_batch_loss=valid_loss.item())\n",
    "\n",
    "            valid_pbar.set_description(desc=f\"val_loss: {valid_loss.item():.4f}\")\n",
    "\n",
    "            valid_targets.extend(targets.cpu().detach().numpy().tolist())\n",
    "            valid_preds.extend(outputs.cpu().detach().numpy().tolist())\n",
    "\n",
    "        # Tidy\n",
    "        del outputs, targets, ids, mask, ttis, valid_loss\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        return valid_preds, valid_targets\n",
    "\n",
    "    def fit(\n",
    "        self,\n",
    "        epochs: int = 10,\n",
    "        output_dir: str = \"/kaggle/working/\",\n",
    "        custom_name: str = \"model.pth\",\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Low-effort alternative for doing the complete training and validation process\n",
    "        \"\"\"\n",
    "        best_loss = int(1e7)\n",
    "        best_preds = None\n",
    "        for epx in range(epochs):\n",
    "            print(f\"{'='*20} Epoch: {epx+1} / {epochs} {'='*20}\")\n",
    "\n",
    "            train_preds, train_targets = self.train_one_epoch()\n",
    "            train_mse = mean_squared_error(train_targets, train_preds)\n",
    "            print(f\"Training loss: {train_mse:.4f}\")\n",
    "\n",
    "            valid_preds, valid_targets = self.valid_one_epoch()\n",
    "            valid_mse = mean_squared_error(valid_targets, valid_preds)\n",
    "            print(f\"Validation loss: {valid_mse:.4f}\")\n",
    "\n",
    "            if self.wandb:\n",
    "                wandb_log(train_mse=train_mse, valid_mse=valid_mse)\n",
    "\n",
    "            if valid_mse < best_loss:\n",
    "                best_loss = valid_mse\n",
    "                self.save_model(output_dir, custom_name)\n",
    "                print(f\"Saved model with val_loss: {best_loss:.4f}\")\n",
    "\n",
    "    def save_model(self, path, name, verbose=False):\n",
    "        \"\"\"\n",
    "        Saves the model at the provided destination\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if not os.path.exists(path):\n",
    "                os.makedirs(path)\n",
    "        except:\n",
    "            print(\"Errors encountered while making the output directory\")\n",
    "\n",
    "        torch.save(self.model.state_dict(), os.path.join(path, name))\n",
    "        if verbose:\n",
    "            print(f\"Model Saved at: {os.path.join(path, name)}\")\n",
    "\n",
    "    def _convert_if_not_tensor(self, x, dtype):\n",
    "        if self._tensor_check(x):\n",
    "            return x.to(self.device, dtype=dtype)\n",
    "        else:\n",
    "            return torch.tensor(x, dtype=dtype, device=self.device)\n",
    "\n",
    "    def _tensor_check(self, x):\n",
    "        return isinstance(x, torch.Tensor)\n",
    "\n",
    "\n",
    "def yield_optimizer(model):\n",
    "    \"\"\"Returns optimizer for specific parameters\"\"\"\n",
    "    param_optimizer = list(model.named_parameters())\n",
    "    no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
    "    optimizer_parameters = [\n",
    "        {\n",
    "            \"params\": [\n",
    "                p for n, p in param_optimizer if not any(nd in n for nd in no_decay)\n",
    "            ],\n",
    "            \"weight_decay\": 0.003,\n",
    "        },\n",
    "        {\n",
    "            \"params\": [\n",
    "                p for n, p in param_optimizer if any(nd in n for nd in no_decay)\n",
    "            ],\n",
    "            \"weight_decay\": 0.0,\n",
    "        },\n",
    "    ]\n",
    "    return transformers.AdamW(optimizer_parameters, lr=Config.LR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Training\n",
    "import platform\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"[INFO] Using GPU: {}\\n\".format(torch.cuda.get_device_name()))\n",
    "    DEVICE = torch.device(\"cuda:0\")\n",
    "else:\n",
    "    print(\"\\n[INFO] GPU not found. Using CPU: {}\\n\".format(platform.processor()))\n",
    "    DEVICE = torch.device(\"cpu\")\n",
    "\n",
    "train_set = AI4CodeDataset(train_df_mark)\n",
    "valid_set = AI4CodeDataset(val_df_mark)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_set, batch_size=Config.TRAIN_BS, shuffle=True, num_workers=8\n",
    ")\n",
    "\n",
    "valid_loader = DataLoader(\n",
    "    valid_set, batch_size=Config.VALID_BS, shuffle=False, num_workers=8\n",
    ")\n",
    "\n",
    "model = BERTLargeModel().to(DEVICE)\n",
    "nb_train_steps = int(len(train_df_mark) / Config.TRAIN_BS * Config.NB_EPOCHS)\n",
    "optimizer = yield_optimizer(model)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "    optimizer, T_0=Config.T_0, eta_min=Config.η_min\n",
    ")\n",
    "train_loss_fn, valid_loss_fn = nn.MSELoss(), nn.MSELoss()\n",
    "\n",
    "if Config.wandb:\n",
    "    wandb.watch(model, criterion=train_loss_fn)\n",
    "\n",
    "trainer = Trainer(\n",
    "    config=Config,\n",
    "    dataloaders=(train_loader, valid_loader),\n",
    "    loss_fns=(train_loss_fn, valid_loss_fn),\n",
    "    optimizer=optimizer,\n",
    "    model=model,\n",
    "    scheduler=scheduler,\n",
    "    wandb=Config.wandb,\n",
    ")\n",
    "\n",
    "best_pred = trainer.fit(epochs=Config.NB_EPOCHS, custom_name=f\"ai4code_bert_large.bin\")\n",
    "\n",
    "if Config.wandb:\n",
    "    run.finish()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `AI4Code Pytorch DistilBert Baseline.ipynb`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import sys, os\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "from tqdm import tqdm\n",
    "\n",
    "pd.options.display.width = 180\n",
    "pd.options.display.max_colwidth = 120\n",
    "\n",
    "BERT_PATH = (\n",
    "    \"../input/huggingface-bert-variants/distilbert-base-uncased/distilbert-base-uncased\"\n",
    ")\n",
    "\n",
    "data_dir = Path(\"../input/AI4Code\")\n",
    "NUM_TRAIN = 10000\n",
    "\n",
    "\n",
    "# Preprocessing\n",
    "def read_notebook(path):\n",
    "    return (\n",
    "        pd.read_json(path, dtype={\"cell_type\": \"category\", \"source\": \"str\"})\n",
    "        .assign(id=path.stem)\n",
    "        .rename_axis(\"cell_id\")\n",
    "    )\n",
    "\n",
    "\n",
    "paths_train = list((data_dir / \"train\").glob(\"*.json\"))[:NUM_TRAIN]\n",
    "notebooks_train = [read_notebook(path) for path in tqdm(paths_train, desc=\"Train NBs\")]\n",
    "df = (\n",
    "    pd.concat(notebooks_train)\n",
    "    .set_index(\"id\", append=True)\n",
    "    .swaplevel()\n",
    "    .sort_index(level=\"id\", sort_remaining=False)\n",
    ")\n",
    "\n",
    "df_orders = pd.read_csv(\n",
    "    data_dir / \"train_orders.csv\",\n",
    "    index_col=\"id\",\n",
    "    squeeze=True,\n",
    ").str.split()  # Split the string representation of cell_ids into a list\n",
    "\n",
    "df_orders_ = df_orders.to_frame().join(\n",
    "    df.reset_index(\"cell_id\").groupby(\"id\")[\"cell_id\"].apply(list),\n",
    "    how=\"right\",\n",
    ")\n",
    "\n",
    "ranks = {\n",
    "    id_: {\"cell_id\": cell_id, \"rank\": get_ranks(cell_order, cell_id)}\n",
    "    for id_, cell_order, cell_id in df_orders_.itertuples()\n",
    "}\n",
    "\n",
    "df_ranks = (\n",
    "    pd.DataFrame.from_dict(ranks, orient=\"index\")\n",
    "    .rename_axis(\"id\")\n",
    "    .apply(pd.Series.explode)\n",
    "    .set_index(\"cell_id\", append=True)\n",
    ")\n",
    "\n",
    "df_ancestors = pd.read_csv(data_dir / \"train_ancestors.csv\", index_col=\"id\")\n",
    "\n",
    "df = (\n",
    "    df.reset_index()\n",
    "    .merge(df_ranks, on=[\"id\", \"cell_id\"])\n",
    "    .merge(df_ancestors, on=[\"id\"])\n",
    ")\n",
    "\n",
    "df[\"pct_rank\"] = df[\"rank\"] / df.groupby(\"id\")[\"cell_id\"].transform(\"count\")\n",
    "\n",
    "# Splitting\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "\n",
    "NVALID = 0.1  # size of validation set\n",
    "\n",
    "splitter = GroupShuffleSplit(n_splits=1, test_size=NVALID, random_state=0)\n",
    "\n",
    "train_ind, val_ind = next(splitter.split(df, groups=df[\"ancestor_id\"]))\n",
    "\n",
    "train_df = df.loc[train_ind].reset_index(drop=True)\n",
    "val_df = df.loc[val_ind].reset_index(drop=True)\n",
    "\n",
    "train_df_mark = train_df[train_df[\"cell_type\"] == \"markdown\"].reset_index(drop=True)\n",
    "val_df_mark = val_df[val_df[\"cell_type\"] == \"markdown\"].reset_index(drop=True)\n",
    "\n",
    "# Model\n",
    "from transformers import DistilBertModel, DistilBertTokenizer\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "MAX_LEN = 128\n",
    "\n",
    "\n",
    "class MarkdownModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MarkdownModel, self).__init__()\n",
    "        self.distill_bert = DistilBertModel.from_pretrained(BERT_PATH)\n",
    "        self.top = nn.Linear(768, 1)\n",
    "\n",
    "    def forward(self, ids, mask):\n",
    "        x = self.distill_bert(ids, mask)[0]\n",
    "        x = self.top(x[:, 0, :])\n",
    "        return x\n",
    "\n",
    "\n",
    "# Dataset\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "\n",
    "class MarkdownDataset(Dataset):\n",
    "    def __init__(self, df, max_len):\n",
    "        super().__init__()\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.max_len = max_len\n",
    "        self.tokenizer = DistilBertTokenizer.from_pretrained(\n",
    "            BERT_PATH, do_lower_case=True\n",
    "        )\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row = self.df.iloc[index]\n",
    "\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            row.source,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            padding=\"max_length\",\n",
    "            return_token_type_ids=True,\n",
    "            truncation=True,\n",
    "        )\n",
    "        ids = torch.LongTensor(inputs[\"input_ids\"])\n",
    "        mask = torch.LongTensor(inputs[\"attention_mask\"])\n",
    "\n",
    "        return ids, mask, torch.FloatTensor([row.pct_rank])\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "\n",
    "\n",
    "train_ds = MarkdownDataset(train_df_mark, max_len=MAX_LEN)\n",
    "val_ds = MarkdownDataset(val_df_mark, max_len=MAX_LEN)\n",
    "\n",
    "# Optimizer\n",
    "def adjust_lr(optimizer, epoch):\n",
    "    if epoch < 1:\n",
    "        lr = 5e-5\n",
    "    elif epoch < 2:\n",
    "        lr = 1e-3\n",
    "    elif epoch < 5:\n",
    "        lr = 1e-4\n",
    "    else:\n",
    "        lr = 1e-5\n",
    "\n",
    "    for p in optimizer.param_groups:\n",
    "        p[\"lr\"] = lr\n",
    "    return lr\n",
    "\n",
    "\n",
    "def get_optimizer(net):\n",
    "    optimizer = torch.optim.Adam(\n",
    "        filter(lambda p: p.requires_grad, net.parameters()),\n",
    "        lr=3e-4,\n",
    "        betas=(0.9, 0.999),\n",
    "        eps=1e-08,\n",
    "    )\n",
    "    return optimizer\n",
    "\n",
    "\n",
    "# DataLoader\n",
    "BS = 32\n",
    "NW = 8\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=BS,\n",
    "    shuffle=True,\n",
    "    num_workers=NW,\n",
    "    pin_memory=False,\n",
    "    drop_last=True,\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_ds,\n",
    "    batch_size=BS,\n",
    "    shuffle=False,\n",
    "    num_workers=NW,\n",
    "    pin_memory=False,\n",
    "    drop_last=False,\n",
    ")\n",
    "\n",
    "# Training\n",
    "def read_data(data):\n",
    "    return tuple(d.cuda() for d in data[:-1]), data[-1].cuda()\n",
    "\n",
    "\n",
    "def validate(model, val_loader):\n",
    "    model.eval()\n",
    "\n",
    "    tbar = tqdm(val_loader, file=sys.stdout)\n",
    "\n",
    "    preds = []\n",
    "    labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, data in enumerate(tbar):\n",
    "            inputs, target = read_data(data)\n",
    "\n",
    "            pred = model(inputs[0], inputs[1])\n",
    "\n",
    "            preds.append(pred.detach().cpu().numpy().ravel())\n",
    "            labels.append(target.detach().cpu().numpy().ravel())\n",
    "\n",
    "    return np.concatenate(labels), np.concatenate(preds)\n",
    "\n",
    "\n",
    "def train(model, train_loader, val_loader, epochs):\n",
    "    np.random.seed(0)\n",
    "\n",
    "    optimizer = get_optimizer(model)\n",
    "\n",
    "    criterion = torch.nn.MSELoss()\n",
    "\n",
    "    for e in range(epochs):\n",
    "        model.train()\n",
    "        tbar = tqdm(train_loader, file=sys.stdout)\n",
    "\n",
    "        lr = adjust_lr(optimizer, e)\n",
    "\n",
    "        loss_list = []\n",
    "        preds = []\n",
    "        labels = []\n",
    "\n",
    "        for idx, data in enumerate(tbar):\n",
    "            inputs, target = read_data(data)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            pred = model(inputs[0], inputs[1])\n",
    "\n",
    "            loss = criterion(pred, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            loss_list.append(loss.detach().cpu().item())\n",
    "            preds.append(pred.detach().cpu().numpy().ravel())\n",
    "            labels.append(target.detach().cpu().numpy().ravel())\n",
    "\n",
    "            avg_loss = np.round(np.mean(loss_list), 4)\n",
    "\n",
    "            tbar.set_description(f\"Epoch {e+1} Loss: {avg_loss} lr: {lr}\")\n",
    "\n",
    "        y_val, y_pred = validate(model, val_loader)\n",
    "\n",
    "        print(\"Validation MSE:\", np.round(mean_squared_error(y_val, y_pred), 4))\n",
    "        print()\n",
    "    return model, y_pred\n",
    "\n",
    "\n",
    "model = MarkdownModel()\n",
    "model = model.cuda()\n",
    "model, y_pred = train(model, train_loader, val_loader, epochs=1)\n",
    "\n",
    "val_df[\"pred\"] = val_df.groupby([\"id\", \"cell_type\"])[\"rank\"].rank(pct=True)\n",
    "val_df.loc[val_df[\"cell_type\"] == \"markdown\", \"pred\"] = y_pred\n",
    "\n",
    "y_dummy = val_df.sort_values(\"pred\").groupby(\"id\")[\"cell_id\"].apply(list)\n",
    "calc_kendall_tau(df_orders.loc[y_dummy.index], y_dummy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test & Submission\n",
    "paths_test = list((data_dir / \"test\").glob(\"*.json\"))\n",
    "notebooks_test = [read_notebook(path) for path in tqdm(paths_test, desc=\"Test NBs\")]\n",
    "test_df = (\n",
    "    pd.concat(notebooks_test)\n",
    "    .set_index(\"id\", append=True)\n",
    "    .swaplevel()\n",
    "    .sort_index(level=\"id\", sort_remaining=False)\n",
    ").reset_index()\n",
    "\n",
    "test_df[\"rank\"] = test_df.groupby([\"id\", \"cell_type\"]).cumcount()\n",
    "test_df[\"pred\"] = test_df.groupby([\"id\", \"cell_type\"])[\"rank\"].rank(pct=True)\n",
    "\n",
    "test_df[\"pct_rank\"] = 0\n",
    "test_ds = MarkdownDataset(\n",
    "    test_df[test_df[\"cell_type\"] == \"markdown\"].reset_index(drop=True), max_len=MAX_LEN\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_ds,\n",
    "    batch_size=BS,\n",
    "    shuffle=False,\n",
    "    num_workers=NW,\n",
    "    pin_memory=False,\n",
    "    drop_last=False,\n",
    ")\n",
    "\n",
    "_, y_test = validate(model, test_loader)\n",
    "test_df.loc[test_df[\"cell_type\"] == \"markdown\", \"pred\"] = y_test\n",
    "\n",
    "sub_df = (\n",
    "    test_df.sort_values(\"pred\")\n",
    "    .groupby(\"id\")[\"cell_id\"]\n",
    "    .apply(lambda x: \" \".join(x))\n",
    "    .reset_index()\n",
    ")\n",
    "sub_df.rename(columns={\"cell_id\": \"cell_order\"}, inplace=True)\n",
    "\n",
    "sub_df.to_csv(\"submission.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
