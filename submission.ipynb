{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PREV_MODELS = [\n",
    "    \"0726-1049-md-graphcodebert-fts-from-graphcodebert-base-scaler-fts/ckpt_003.pth\",\n",
    "    \"0724-1749-md-graphcodebert-fts-from-graphcodebert-base-scaler-fts/ckpt_003.pth\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from os import path as osp\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from torch.nn import DataParallel\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "import transformers as tx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    device = \"cuda\"\n",
    "    input_dir = Path(\"../input/AI4Code/\")\n",
    "    working_dir = Path(\"../input/ai4code-model/\")\n",
    "\n",
    "    data_type = \"md\"\n",
    "\n",
    "    md_max_len = 128\n",
    "    py_max_len = 23\n",
    "    total_max_len = 512\n",
    "    num_workers = 2\n",
    "    batch_size = 64\n",
    "    seed = 42\n",
    "\n",
    "    # try:\n",
    "    #     base_model = str(prev_model).split(\"/\")[0].split(\"-\")[3]\n",
    "    # except:\n",
    "    #     base_model = str(prev_model).split(\"/\")[0].split(\"-\")[0]\n",
    "\n",
    "    # if base_model == \"codebert\":\n",
    "    #     model_path = \"microsoft/codebert-base\"\n",
    "    # elif base_model == \"graphcodebert\":\n",
    "    #     model_path = \"microsoft/graphcodebert-base\"\n",
    "    # elif base_model == \"codet5\":\n",
    "    #     model_path = \"Salesforce/codet5-base\"\n",
    "\n",
    "\n",
    "config = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(config):\n",
    "    data_path = list((config.input_dir / \"test\").glob(\"*.json\"))\n",
    "    notebooks = [\n",
    "        read_notebook(path)\n",
    "        for path in tqdm(data_path, desc=\"Reading notebooks\")\n",
    "    ]\n",
    "\n",
    "    df = (\n",
    "        pd.concat(notebooks)\n",
    "        .set_index(\"id\", append=True)\n",
    "        .swaplevel()\n",
    "        .sort_index(level=\"id\", sort_remaining=False)\n",
    "    )\n",
    "\n",
    "    df_test = df.reset_index().dropna()\n",
    "\n",
    "    df_test[\"rank\"] = df_test.groupby([\"id\", \"cell_type\"]).cumcount()\n",
    "    df_test[\"pred\"] = df_test.groupby([\"id\", \"cell_type\"])[\"rank\"].rank(\n",
    "        pct=True\n",
    "    )\n",
    "    df_test[\"pct_rank\"] = 0\n",
    "\n",
    "    df_test_py = (\n",
    "        df_test[df_test[\"cell_type\"] == \"code\"].dropna().reset_index(drop=True)\n",
    "    )\n",
    "    df_test_md = (\n",
    "        df_test[df_test[\"cell_type\"] == \"markdown\"]\n",
    "        .dropna()\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    fts_test = get_features(df_test)\n",
    "\n",
    "    return df_test, df_test_md, df_test_py, fts_test\n",
    "\n",
    "\n",
    "def read_notebook(path):\n",
    "    return (\n",
    "        pd.read_json(path, dtype={\"cell_type\": \"category\", \"source\": \"str\"})\n",
    "        .assign(id=path.stem)\n",
    "        .rename_axis(\"cell_id\")\n",
    "    )\n",
    "\n",
    "\n",
    "def get_ranks(base, derived):\n",
    "    return [base.index(d) for d in derived]\n",
    "\n",
    "\n",
    "def clean_code(cell):\n",
    "    return str(cell).replace(\"\\\\n\", \"\\n\")\n",
    "\n",
    "\n",
    "def sample_cells(cells, sample_size=20):\n",
    "    cells = [clean_code(cell) for cell in cells]\n",
    "    if sample_size >= len(cells):\n",
    "        return [cell[:200] for cell in cells]\n",
    "    else:\n",
    "        step = len(cells) / sample_size\n",
    "        idx = 0\n",
    "        samples = []\n",
    "        while int(np.round(idx)) < len(cells):\n",
    "            samples.append(cells[int(np.round(idx))])\n",
    "            idx += step\n",
    "        assert cells[0] in samples\n",
    "        if cells[-1] not in samples:\n",
    "            samples[-1] = cells[-1]\n",
    "        return samples\n",
    "\n",
    "\n",
    "def get_features(df):\n",
    "    features = {}\n",
    "    df = df.sort_values(\"rank\").reset_index(drop=True)\n",
    "    for idx, sub_df in tqdm(df.groupby(\"id\")):\n",
    "        total_md = sub_df[sub_df.cell_type == \"markdown\"].shape[0]\n",
    "        code_sub_df = sub_df[sub_df.cell_type == \"code\"]\n",
    "        total_code = code_sub_df.shape[0]\n",
    "        codes = sample_cells(code_sub_df.source.values, 20)\n",
    "        features[idx] = {\n",
    "            \"total_code\": total_code,\n",
    "            \"total_md\": total_md,\n",
    "            \"codes\": codes,\n",
    "        }\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NotebookDataset(Dataset):\n",
    "    def __init__(self, df, fts, config):\n",
    "        super().__init__()\n",
    "\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.fts = fts\n",
    "        self.config = config\n",
    "\n",
    "        self.tokenizer = tx.AutoTokenizer.from_pretrained(config.model_path)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.df.iloc[idx]\n",
    "\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            item.source,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_token_type_ids=True,\n",
    "            max_length=self.config.md_max_len,\n",
    "        )\n",
    "        code_inputs = self.tokenizer.batch_encode_plus(\n",
    "            [str(x) for x in self.fts[item.id][\"codes\"]],\n",
    "            add_special_tokens=True,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            max_length=self.config.py_max_len,\n",
    "        )\n",
    "\n",
    "        n_md = self.fts[item.id][\"total_md\"]\n",
    "        n_code = self.fts[item.id][\"total_md\"]\n",
    "\n",
    "        if n_md + n_code == 0:\n",
    "            fts = torch.FloatTensor([0])\n",
    "        else:\n",
    "            fts = torch.FloatTensor([n_md / (n_md + n_code)])\n",
    "\n",
    "        ids = inputs[\"input_ids\"]\n",
    "        for x in code_inputs[\"input_ids\"]:\n",
    "            ids.extend(x[:-1])\n",
    "        ids = ids[: self.config.total_max_len]\n",
    "        if len(ids) != self.config.total_max_len:\n",
    "            ids = ids + [\n",
    "                self.tokenizer.pad_token_id,\n",
    "            ] * (self.config.total_max_len - len(ids))\n",
    "        ids = torch.LongTensor(ids)\n",
    "\n",
    "        mask = inputs[\"attention_mask\"]\n",
    "        for x in code_inputs[\"attention_mask\"]:\n",
    "            mask.extend(x[:-1])\n",
    "        mask = mask[: self.config.total_max_len]\n",
    "        if len(mask) != self.config.total_max_len:\n",
    "            mask = mask + [\n",
    "                self.tokenizer.pad_token_id,\n",
    "            ] * (self.config.total_max_len - len(mask))\n",
    "        mask = torch.LongTensor(mask)\n",
    "\n",
    "        return ids, mask, fts\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(config):\n",
    "    model = NotebookArranger(tx.AutoModel.from_pretrained(config.model_path))\n",
    "    model.load_state_dict(torch.load(config.working_dir / config.prev_model))\n",
    "    return model.to(config.device)\n",
    "\n",
    "\n",
    "class NotebookArranger(nn.Module):\n",
    "    def __init__(self, pretrained_model):\n",
    "        super().__init__()\n",
    "        self.model = pretrained_model\n",
    "        self.fc = nn.Linear(769, 1)\n",
    "\n",
    "    def forward(self, ids, mask, fts):\n",
    "        x = self.model(ids, mask)[0]\n",
    "        y = self.fc(torch.cat((x[:, 0, :], fts), 1))\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, dataloader, config):\n",
    "    model.eval()\n",
    "\n",
    "    tbar = tqdm(dataloader, total=len(dataloader))\n",
    "\n",
    "    preds = []\n",
    "    with torch.no_grad():\n",
    "        for _, data in enumerate(tbar):\n",
    "            ids = data[0].to(config.device)\n",
    "            mask = data[1].to(config.device)\n",
    "            fts = data[2].to(config.device)\n",
    "\n",
    "            pred = model(ids=ids, mask=mask, fts=fts).view(-1)\n",
    "\n",
    "            preds.append(pred.detach().cpu().numpy().ravel())\n",
    "\n",
    "    return np.concatenate(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "df_test, df_test_md, df_test_py, fts_test = preprocess(config)\n",
    "\n",
    "if config.data_type == \"all\":\n",
    "    df_testset = df_test\n",
    "elif config.data_type == \"md\":\n",
    "    df_testset = df_test_md\n",
    "elif config.data_type == \"py\":\n",
    "    df_testset = df_test_py\n",
    "\n",
    "testset = NotebookDataset(df_testset, fts=fts_test, config=config)\n",
    "testloader = DataLoader(\n",
    "    testset,\n",
    "    batch_size=config.batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=config.num_workers,\n",
    "    drop_last=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Model and Test\n",
    "dfs, num_models = [], len(PREV_MODELS)\n",
    "for i, prev_model in enumerate(PREV_MODELS):\n",
    "    config.prev_model = prev_model\n",
    "\n",
    "    model = get_model(config)\n",
    "\n",
    "    y_test = test(model, testloader, config)\n",
    "\n",
    "    if config.data_type == \"all\":\n",
    "        df_test[\"pred\"] = y_test\n",
    "    elif config.data_type == \"md\":\n",
    "        df_test.loc[df_test[\"cell_type\"] == \"markdown\", \"pred\"] = y_test\n",
    "    elif config.data_type == \"py\":\n",
    "        df_test.loc[df_test[\"cell_type\"] == \"code\", \"pred\"] = y_test\n",
    "\n",
    "    df_pred = (\n",
    "        df_test.sort_values(\"pred\")\n",
    "        .groupby(\"id\")[\"cell_id\"]\n",
    "        .apply(lambda x: \" \".join(x))\n",
    "        .reset_index()\n",
    "    )\n",
    "    df_pred.rename(columns={\"cell_id\": \"cell_order\"}, inplace=True)\n",
    "\n",
    "    dfs.append(df_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensemble\n",
    "df_1, len_df_1, num_dfs = dfs[0], len(dfs[0]), len(dfs)\n",
    "\n",
    "ensembled_order = []\n",
    "for idx in range(len_df_1):\n",
    "    ensembled_sample = {\n",
    "        k: v / num_dfs  # TBD weighted based on performance?\n",
    "        for v, k in enumerate(df_1.iloc[idx][\"cell_order\"].split(\" \"))\n",
    "    }\n",
    "    for df in dfs[1:]:\n",
    "        sample = {\n",
    "            k: v / num_dfs\n",
    "            for v, k in enumerate(df.iloc[idx][\"cell_order\"].split(\" \"))\n",
    "        }\n",
    "        for key in ensembled_sample:\n",
    "            ensembled_sample[key] += sample[key]\n",
    "    ensembled_order.append(\n",
    "        \" \".join(\n",
    "            [\n",
    "                i[0]\n",
    "                for i in list(\n",
    "                    sorted(ensembled_sample.items(), key=lambda x: x[1])\n",
    "                )\n",
    "            ]\n",
    "        )\n",
    "    )\n",
    "df_1[\"cell_order\"] = ensembled_order\n",
    "\n",
    "df_1.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.12 ('ai4code-EsLDQqrx-py3.7')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b482d39f4197d146cfb2ad437711e28b89509dfa0cfcefa8ffca945d6c1c8c9c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
