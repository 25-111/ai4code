{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATHS = [\"0716-1258-md-codebert-from-codebert-base-scaler/ckpt_002.pth\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from os import path as osp\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from torch.nn import DataParallel\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "import transformers as tx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    device = \"cuda\"\n",
    "    input_dir = Path(\"../input/AI4Code/\")\n",
    "    working_dir = Path(\"../input/ai4code-model/\")\n",
    "\n",
    "    data_type = \"md\"\n",
    "\n",
    "    optim = [\"AdamW\"][0]\n",
    "    loss = [\"MSE\"][0]\n",
    "    valid_ratio = 0.1\n",
    "    max_len = 256\n",
    "    num_epochs = 3\n",
    "    num_workers = 2\n",
    "    batch_size = 192\n",
    "    lr = 3e-4\n",
    "    accum_steps = 4\n",
    "    seed = 42\n",
    "\n",
    "    mode = \"test\"\n",
    "\n",
    "\n",
    "config = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(config):\n",
    "    if not osp.exists(config.input_dir / f\"{config.mode}.csv\"):\n",
    "        data_path = list((config.input_dir / config.mode).glob(\"*.json\"))\n",
    "        notebooks = [\n",
    "            read_notebook(path)\n",
    "            for path in tqdm(data_path, desc=\"Reading notebooks\")\n",
    "        ]\n",
    "\n",
    "        df = (\n",
    "            pd.concat(notebooks)\n",
    "            .set_index(\"id\", append=True)\n",
    "            .swaplevel()\n",
    "            .sort_index(level=\"id\", sort_remaining=False)\n",
    "        )\n",
    "\n",
    "        if config.mode == \"train\":\n",
    "            df_orders = pd.read_csv(\n",
    "                config.input_dir / \"train_orders.csv\",\n",
    "                index_col=\"id\",\n",
    "                squeeze=True,\n",
    "            ).str.split()\n",
    "\n",
    "            df_orders_ = df_orders.to_frame().join(\n",
    "                df.reset_index(\"cell_id\").groupby(\"id\")[\"cell_id\"].apply(list),\n",
    "                how=\"right\",\n",
    "            )\n",
    "\n",
    "            ranks = {\n",
    "                id_: {\n",
    "                    \"cell_id\": cell_id,\n",
    "                    \"rank\": get_ranks(cell_order, cell_id),\n",
    "                }\n",
    "                for id_, cell_order, cell_id in df_orders_.itertuples()\n",
    "            }\n",
    "            df_ranks = (\n",
    "                pd.DataFrame.from_dict(ranks, orient=\"index\")\n",
    "                .rename_axis(\"id\")\n",
    "                .apply(pd.Series.explode)\n",
    "                .set_index(\"cell_id\", append=True)\n",
    "            )\n",
    "\n",
    "            df_ancestors = pd.read_csv(\n",
    "                config.input_dir / \"train_ancestors.csv\", index_col=\"id\"\n",
    "            )\n",
    "            df = (\n",
    "                df.reset_index()\n",
    "                .merge(df_ranks, on=[\"id\", \"cell_id\"])\n",
    "                .merge(df_ancestors, on=[\"id\"])\n",
    "            )\n",
    "            df[\"pct_rank\"] = df[\"rank\"] / df.groupby(\"id\")[\n",
    "                \"cell_id\"\n",
    "            ].transform(\"count\")\n",
    "\n",
    "            splitter = GroupShuffleSplit(\n",
    "                n_splits=1,\n",
    "                test_size=config.valid_ratio,\n",
    "                random_state=config.seed,\n",
    "            )\n",
    "            idx_train, idx_valid = next(\n",
    "                splitter.split(df, groups=df[\"ancestor_id\"])\n",
    "            )\n",
    "\n",
    "            df_train = df.loc[idx_train].reset_index(drop=True).dropna()\n",
    "            df_valid = df.loc[idx_valid].reset_index(drop=True).dropna()\n",
    "\n",
    "            df_train_py = (\n",
    "                df_train[df_train[\"cell_type\"] == \"code\"]\n",
    "                .drop(\"parent_id\", axis=1)\n",
    "                .dropna()\n",
    "                .reset_index(drop=True)\n",
    "            )\n",
    "            df_valid_py = (\n",
    "                df_valid[df_valid[\"cell_type\"] == \"code\"]\n",
    "                .drop(\"parent_id\", axis=1)\n",
    "                .dropna()\n",
    "                .reset_index(drop=True)\n",
    "            )\n",
    "            df_train_md = (\n",
    "                df_train[df_train[\"cell_type\"] == \"markdown\"]\n",
    "                .drop(\"parent_id\", axis=1)\n",
    "                .dropna()\n",
    "                .reset_index(drop=True)\n",
    "            )\n",
    "            df_valid_md = (\n",
    "                df_valid[df_valid[\"cell_type\"] == \"markdown\"]\n",
    "                .drop(\"parent_id\", axis=1)\n",
    "                .dropna()\n",
    "                .reset_index(drop=True)\n",
    "            )\n",
    "\n",
    "            fts_train = get_features(df_train)\n",
    "            fts_valid = get_features(df_valid)\n",
    "\n",
    "            df_train.to_csv(config.input_dir / \"train.csv\", index=False)\n",
    "            df_valid.to_csv(config.input_dir / \"valid.csv\", index=False)\n",
    "            df_train_md.to_csv(config.input_dir / \"train_md.csv\", index=False)\n",
    "            df_valid_md.to_csv(config.input_dir / \"valid_md.csv\", index=False)\n",
    "            df_train_py.to_csv(config.input_dir / \"train_py.csv\", index=False)\n",
    "            df_valid_py.to_csv(config.input_dir / \"valid_py.csv\", index=False)\n",
    "            json.dump(\n",
    "                open(config.input_dir / \"train_fts.json\", \"w\"), fts_train\n",
    "            )\n",
    "            json.dump(\n",
    "                open(config.input_dir / \"valid_fts.json\", \"w\"), fts_valid\n",
    "            )\n",
    "\n",
    "            return (\n",
    "                df_train,\n",
    "                df_valid,\n",
    "                df_train_md,\n",
    "                df_valid_md,\n",
    "                df_train_py,\n",
    "                df_valid_py,\n",
    "                fts_train,\n",
    "                fts_valid,\n",
    "                df_orders,\n",
    "            )\n",
    "\n",
    "        elif config.mode == \"test\":\n",
    "            df_test = (\n",
    "                (\n",
    "                    pd.concat(notebooks)\n",
    "                    .set_index(\"id\", append=True)\n",
    "                    .swaplevel()\n",
    "                    .sort_index(level=\"id\", sort_remaining=False)\n",
    "                )\n",
    "                .reset_index(drop=True)\n",
    "                .dropna()\n",
    "            )\n",
    "\n",
    "            df_test[\"rank\"] = df_test.groupby([\"id\", \"cell_type\"]).cumcount()\n",
    "            df_test[\"pred\"] = df_test.groupby([\"id\", \"cell_type\"])[\n",
    "                \"rank\"\n",
    "            ].rank(pct=True)\n",
    "            df_test[\"pct_rank\"] = 0\n",
    "\n",
    "            df_test_py = (\n",
    "                df_test[df_test[\"cell_type\"] == \"code\"]\n",
    "                .drop(\"parent_id\", axis=1)\n",
    "                .dropna()\n",
    "                .reset_index(drop=True)\n",
    "            )\n",
    "            df_test_md = (\n",
    "                df_test[df_test[\"cell_type\"] == \"markdown\"]\n",
    "                .drop(\"parent_id\", axis=1)\n",
    "                .dropna()\n",
    "                .reset_index(drop=True)\n",
    "            )\n",
    "\n",
    "            fts_test = get_features(df_test)\n",
    "\n",
    "            df_test.to_csv(config.input_dir / \"test.csv\", index=False)\n",
    "            df_test_md.to_csv(config.input_dir / \"test_md.csv\", index=False)\n",
    "            df_test_py.to_csv(config.input_dir / \"test_py.csv\", index=False)\n",
    "            json.dump(open(config.input_dir / \"test_fts.json\", \"w\"), fts_test)\n",
    "\n",
    "            return df_test, df_test_md, df_test_py, fts_test\n",
    "\n",
    "    else:\n",
    "        if config.mode == \"train\":\n",
    "            df_train = pd.read_csv(config.input_dir / \"train.csv\").reset_index(\n",
    "                drop=True\n",
    "            )\n",
    "            df_valid = pd.read_csv(config.input_dir / \"valid.csv\").reset_index(\n",
    "                drop=True\n",
    "            )\n",
    "            df_train_md = pd.read_csv(\n",
    "                config.input_dir / \"train_md.csv\"\n",
    "            ).reset_index(drop=True)\n",
    "            df_valid_md = pd.read_csv(\n",
    "                config.input_dir / \"valid_md.csv\"\n",
    "            ).reset_index(drop=True)\n",
    "            df_train_py = pd.read_csv(\n",
    "                config.input_dir / \"train_py.csv\"\n",
    "            ).reset_index(drop=True)\n",
    "            df_valid_py = pd.read_csv(\n",
    "                config.input_dir / \"valid_py.csv\"\n",
    "            ).reset_index(drop=True)\n",
    "            fts_train = json.load(\n",
    "                open(config.input_dir / \"train_fts.json\", \"r\")\n",
    "            )\n",
    "            fts_valid = json.load(\n",
    "                open(config.input_dir / \"valid_fts.json\", \"r\")\n",
    "            )\n",
    "            df_orders = pd.read_csv(\n",
    "                config.input_dir / \"train_orders.csv\",\n",
    "                index_col=\"id\",\n",
    "                squeeze=True,\n",
    "            ).str.split()\n",
    "            return (\n",
    "                df_train,\n",
    "                df_valid,\n",
    "                df_train_md,\n",
    "                df_valid_md,\n",
    "                df_train_py,\n",
    "                df_valid_py,\n",
    "                fts_train,\n",
    "                fts_valid,\n",
    "                df_orders,\n",
    "            )\n",
    "\n",
    "        elif config.mode == \"test\":\n",
    "            df_test = pd.read_csv(config.input_dir / \"test.csv\").reset_index(\n",
    "                drop=True\n",
    "            )\n",
    "            df_test_md = pd.read_csv(\n",
    "                config.input_dir / \"test_md.csv\"\n",
    "            ).reset_index(drop=True)\n",
    "            df_test_py = pd.read_csv(\n",
    "                config.input_dir / \"test_py.csv\"\n",
    "            ).reset_index(drop=True)\n",
    "            fts_test = json.load(open(config.input_dir / \"test_fts.json\", \"r\"))\n",
    "            return df_test, df_test_md, df_test_py, fts_test\n",
    "\n",
    "\n",
    "def read_notebook(path):\n",
    "    return (\n",
    "        pd.read_json(path, dtype={\"cell_type\": \"category\", \"source\": \"str\"})\n",
    "        .assign(id=path.stem)\n",
    "        .rename_axis(\"cell_id\")\n",
    "    )\n",
    "\n",
    "\n",
    "def get_ranks(base, derived):\n",
    "    return [base.index(d) for d in derived]\n",
    "\n",
    "\n",
    "def clean_code(cell):\n",
    "    return str(cell).replace(\"\\\\n\", \"\\n\")\n",
    "\n",
    "\n",
    "def sample_cells(cells, sample_size=20):\n",
    "    cells = [clean_code(cell) for cell in cells]\n",
    "    if sample_size >= len(cells):\n",
    "        return [cell[:200] for cell in cells]\n",
    "    else:\n",
    "        step = len(cells) / sample_size\n",
    "        idx = 0\n",
    "        samples = []\n",
    "        while int(np.round(idx)) < len(cells):\n",
    "            samples.append(cells[int(np.round(idx))])\n",
    "            idx += step\n",
    "        assert cells[0] in samples\n",
    "        if cells[-1] not in samples:\n",
    "            samples[-1] = cells[-1]\n",
    "        return samples\n",
    "\n",
    "\n",
    "def get_features(df):\n",
    "    features = {}\n",
    "    df = df.sort_values(\"rank\").reset_index(drop=True)\n",
    "    for idx, sub_df in tqdm(df.groupby(\"id\")):\n",
    "        total_md = sub_df[sub_df.cell_type == \"markdown\"].shape[0]\n",
    "        code_sub_df = sub_df[sub_df.cell_type == \"code\"]\n",
    "        total_code = code_sub_df.shape[0]\n",
    "        codes = sample_cells(code_sub_df.source.values, 20)\n",
    "        features[idx] = {\n",
    "            \"total_code\": total_code,\n",
    "            \"total_md\": total_md,\n",
    "            \"codes\": codes,\n",
    "        }\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NotebookDataset(Dataset):\n",
    "    def __init__(self, df, fts, config):\n",
    "        super().__init__()\n",
    "\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.fts = fts\n",
    "        self.config = config\n",
    "\n",
    "        self.tokenizer = tx.AutoTokenizer.from_pretrained(config.model_path)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.df.iloc[idx]\n",
    "\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            item.source,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_token_type_ids=True,\n",
    "            max_length=self.config.max_len,\n",
    "        )\n",
    "        code_inputs = self.tokenizer.batch_encode_plus(\n",
    "            [str(x) for x in self.fts[item.id][\"codes\"]],\n",
    "            add_special_tokens=True,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            max_length=23,\n",
    "        )\n",
    "\n",
    "        n_md = self.fts[item.id][\"total_md\"]\n",
    "        n_code = self.fts[item.id][\"total_md\"]\n",
    "\n",
    "        if n_md + n_code == 0:\n",
    "            fts = torch.FloatTensor([0])\n",
    "        else:\n",
    "            fts = torch.FloatTensor([n_md / (n_md + n_code)])\n",
    "\n",
    "        ids = inputs[\"input_ids\"]\n",
    "        for x in code_inputs[\"input_ids\"]:\n",
    "            ids.extend(x[:-1])\n",
    "        ids = ids[: self.total_max_len]\n",
    "        if len(ids) != self.total_max_len:\n",
    "            ids = ids + [\n",
    "                self.tokenizer.pad_token_id,\n",
    "            ] * (self.total_max_len - len(ids))\n",
    "        ids = torch.LongTensor(ids)\n",
    "\n",
    "        mask = inputs[\"attention_mask\"]\n",
    "        for x in code_inputs[\"attention_mask\"]:\n",
    "            mask.extend(x[:-1])\n",
    "        mask = mask[: self.total_max_len]\n",
    "        if len(mask) != self.total_max_len:\n",
    "            mask = mask + [\n",
    "                self.tokenizer.pad_token_id,\n",
    "            ] * (self.total_max_len - len(mask))\n",
    "        mask = torch.LongTensor(mask)\n",
    "\n",
    "        if self.config.mode == \"train\":\n",
    "            target = torch.FloatTensor([item.pct_rank])\n",
    "            return ids, mask, fts, target\n",
    "        else:\n",
    "            return ids, mask, fts\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(config):\n",
    "    model = NotebookArranger(tx.AutoModel.from_pretrained(config.model_path))\n",
    "\n",
    "    try:\n",
    "        model.load_state_dict(\n",
    "            torch.load(\n",
    "                config.working_dir / config.base_model / config.prev_model\n",
    "            )\n",
    "        )\n",
    "    except:\n",
    "        print(\n",
    "            f\"There is no {config.prev_model}, use base {config.base_model} instead\"\n",
    "        )\n",
    "\n",
    "    if config.mode == \"train\":\n",
    "        model = DataParallel(model, device_ids=[0, 1, 2, 3])\n",
    "    return model.to(config.device)\n",
    "\n",
    "\n",
    "class NotebookArranger(nn.Module):\n",
    "    def __init__(self, pretrained_model):\n",
    "        super().__init__()\n",
    "        self.model = pretrained_model\n",
    "        self.fc = nn.Linear(769, 1)\n",
    "\n",
    "    def forward(self, ids, mask, fts):\n",
    "        x = self.model(ids, mask)[0]\n",
    "        y = self.fc(torch.cat((x[:, 0, :], fts), 1))\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, dataloader, config):\n",
    "    model.eval()\n",
    "\n",
    "    tbar = tqdm(dataloader, total=len(dataloader))\n",
    "\n",
    "    preds = []\n",
    "    with torch.no_grad():\n",
    "        for _, data in enumerate(tbar):\n",
    "            ids = data[0].to(config.device)\n",
    "            mask = data[1].to(config.device)\n",
    "            fts = data[2].to(config.device)\n",
    "\n",
    "            pred = model(ids=ids, mask=mask, fts=fts).view(-1)\n",
    "\n",
    "            preds.append(pred.detach().cpu().numpy().ravel())\n",
    "\n",
    "    return np.concatenate(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Loading Data..: Start\")\n",
    "df_test, df_test_md, df_test_py, fts_test = preprocess(config)\n",
    "\n",
    "if config.data_type == \"all\":\n",
    "    df_testset = df_test\n",
    "elif config.data_type == \"md\":\n",
    "    df_testset = df_test_md\n",
    "elif config.data_type == \"py\":\n",
    "    df_testset = df_test_py\n",
    "\n",
    "testset = NotebookDataset(df_testset, fts=fts_test, config=config)\n",
    "testloader = DataLoader(\n",
    "    testset,\n",
    "    batch_size=config.batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=config.num_workers,\n",
    "    drop_last=False,\n",
    ")\n",
    "print(\"Loading Data..: Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs, num_models = [], len(MODEL_PATHS)\n",
    "for i, model_path in enumerate(MODEL_PATHS):\n",
    "    print(f\"Loading Model {i} / {num_models}..: Start\")\n",
    "    tokenizer, model = get_model(config)\n",
    "    print(f\"Loading Model {i} / {num_models}..: Done!\")\n",
    "\n",
    "    print(f\"Testing Model {i} / {num_models}..: Start\")\n",
    "    y_test = test(model, testloader, config)\n",
    "\n",
    "    if config.data_type == \"all\":\n",
    "        df_test[\"pred\"] = y_test\n",
    "    elif config.data_type == \"md\":\n",
    "        df_test.loc[df_test[\"cell_type\"] == \"markdown\", \"pred\"] = y_test\n",
    "    elif config.data_type == \"py\":\n",
    "        df_test.loc[df_test[\"cell_type\"] == \"code\", \"pred\"] = y_test\n",
    "\n",
    "    df_pred = (\n",
    "        df_test.sort_values(\"pred\")\n",
    "        .groupby(\"id\")[\"cell_id\"]\n",
    "        .apply(lambda x: \" \".join(x))\n",
    "        .reset_index()\n",
    "    )\n",
    "    df_pred.rename(columns={\"cell_id\": \"cell_order\"}, inplace=True)\n",
    "\n",
    "    dfs.append(df_pred)\n",
    "    print(f\"Testing Model {i} / {num_models}..: Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Ensemble..: Start\")\n",
    "df_1, len_df_1, num_dfs = dfs[0], len(dfs[0]), len(dfs)\n",
    "\n",
    "ensembled_order = []\n",
    "for idx in range(len_df_1):\n",
    "    ensembled_sample = {\n",
    "        k: v / num_dfs  # TBD weighted based on performance?\n",
    "        for v, k in enumerate(df_1.iloc[idx][\"cell_order\"].split(\" \"))\n",
    "    }\n",
    "    for df in dfs[1:]:\n",
    "        sample = {\n",
    "            k: v / num_dfs\n",
    "            for v, k in enumerate(df.iloc[idx][\"cell_order\"].split(\" \"))\n",
    "        }\n",
    "        for key in ensembled_sample:\n",
    "            ensembled_sample[key] += sample[key]\n",
    "    ensembled_order.append(\n",
    "        \" \".join(\n",
    "            [\n",
    "                i[0]\n",
    "                for i in list(\n",
    "                    sorted(ensembled_sample.items(), key=lambda x: x[1])\n",
    "                )\n",
    "            ]\n",
    "        )\n",
    "    )\n",
    "df_1[\"cell_order\"] = ensembled_order\n",
    "\n",
    "df_1.to_csv(\"submission.csv\", index=False)\n",
    "print(\"Ensemble..: Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.12 ('ai4code-EsLDQqrx-py3.7')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b482d39f4197d146cfb2ad437711e28b89509dfa0cfcefa8ffca945d6c1c8c9c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
